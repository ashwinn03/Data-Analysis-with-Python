{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN algorithm and Conformal Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading data set from iris and ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy.linalg as la\n",
    "\n",
    "iris=load_iris()\n",
    "X=np.genfromtxt(\"//home/cim/pgt/mhac062/Downloads/ionosphere.txt\",delimiter=\",\",usecols=np.arange(34))\n",
    "y=np.genfromtxt(\"//home/cim/pgt/mhac062/Downloads/ionosphere.txt\",delimiter=\",\",usecols=34,dtype='int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN function build for general (K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding index of sorted array  \n",
    "def sorting_array(arr):\n",
    "    n=arr.shape[0]\n",
    "    sort_index=np.zeros(n)\n",
    "    count=0\n",
    "    for j in range(n):\n",
    "        result = 0\n",
    "        for i in range(n): \n",
    "            if (arr[i] < arr[j]): \n",
    "                result += 1\n",
    "            if (arr[i] == arr[j] and i < j): \n",
    "                result += 1\n",
    "        \n",
    "        sort_index[count]=result\n",
    "        count+=1\n",
    "    return sort_index\n",
    "\n",
    "# finding k nearest values  \n",
    "def fetch_k_values(arr,k):\n",
    "    k_values=np.zeros(k)\n",
    "    count=0\n",
    "    for v in range(y_train.shape[0]):\n",
    "        if arr[0,v,0]<=k-1:\n",
    "            k_values[count]=arr[0,v,1]\n",
    "            count+=1\n",
    "    return k_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "predicted in:  3.19 seconds\n",
      "number of errors:  13\n",
      "error_rate:  0.14772727272727273\n"
     ]
    }
   ],
   "source": [
    "# Knn function definition \n",
    "def NNfit(X_train,y_train,X_test,y_test,k):\n",
    "    import time\n",
    "    import numpy.linalg as la\n",
    "    start = time.time()\n",
    "    y_predict=np.zeros(y_test.shape[0])\n",
    "    # finding distance between test samples and training set \n",
    "    for i in range(X_test.shape[0]):\n",
    "        my_array=np.zeros(X_train.shape[0])\n",
    "        for j in range(X_train.shape[0]):\n",
    "            my_array[j]=la.norm(X_test[i,:]-X_train[j,:])\n",
    "    # sorting the array and finding the index    \n",
    "        sorted_array=sorting_array(my_array)\n",
    "    # zipping sorted array with the labels      \n",
    "        d=np.dstack((sorted_array,y_train)) \n",
    "    # finding the k nearest sample labels      \n",
    "        max_label_count=fetch_k_values(d,k)\n",
    "    # voting of lables\n",
    "        (values,counts) = np.unique(max_label_count,return_counts=True)\n",
    "        ind=np.argmax(counts)\n",
    "        y_predict[i]=int(values[ind])     \n",
    "   \n",
    "    \n",
    "    print('\\npredicted in: ',\"%.2f\" %(time.time() - start),\"seconds\")    \n",
    "     # finding number of errors \n",
    "    print('number of errors: ',y_test.size-np.count_nonzero(y_predict == y_test))\n",
    "     # finding the error_rate  \n",
    "    print('error_rate: ',(y_test.size-np.count_nonzero(y_predict == y_test))/y_test.shape[0])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iris_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(iris['data'],iris['target'],random_state=503)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  comparison with  sklearn.neighbors library-iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** My implementation- Result ****\n",
      "\n",
      "\n",
      "predicted in:  3.14 seconds\n",
      "number of errors:  13\n",
      "error_rate:  0.14772727272727273\n",
      "\n",
      "s**** klearn.neighbors - Result ****\n",
      "\n",
      "\n",
      "predicted in:  0.00 seconds\n",
      "number of errors:  13\n",
      "test_error_rate:  0.147727272727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"**** My implementation- Result ****\\n\")\n",
    "NNfit(X_train,y_train,X_test,y_test,3)\n",
    "print(\"\\ns**** klearn.neighbors - Result ****\\n\")\n",
    "import time\n",
    "start = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('\\npredicted in: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "\n",
    "print(\"number of errors: \",y_test.size-np.count_nonzero(y_pred == y_test))\n",
    "\n",
    "print(\"test_error_rate: \",1-knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting inonosphere data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=503)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  comparison with  sklearn.neighbors library-ionosphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** My implementation- Result **** \n",
      "\n",
      "\n",
      "predicted in:  3.18 seconds\n",
      "number of errors:  13\n",
      "error_rate:  0.14772727272727273\n",
      "\n",
      "**** sklearn.neighbors - Result **** \n",
      "\n",
      "\n",
      "predicted in:  0.00 seconds\n",
      "number of errors:  13\n",
      "test_error_rate:  0.147727272727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"**** My implementation- Result **** \\n\")\n",
    "NNfit(X_train,y_train,X_test,y_test,3)\n",
    "print(\"\\n**** sklearn.neighbors - Result **** \\n\")\n",
    "import time\n",
    "start = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('\\npredicted in: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "\n",
    "print(\"number of errors: \",y_test.size-np.count_nonzero(y_pred == y_test))\n",
    "\n",
    "print(\"test_error_rate: \",1-knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conformal prediction \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definition - calculation of confirmity score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition along with parameters\n",
    "def conformity_score(X_train,y_train,X_test,y_test,i,j,labels):\n",
    "    \n",
    "    import math\n",
    "    # concatenating (X,y) of training set\n",
    "    x_train_concat=np.concatenate((X_train,y_train[:,None]),axis=1)\n",
    "    # concatenating (X,y) of one test set per function\n",
    "    x_test_add=np.concatenate((X_test[i:i+1,],labels[j:j+1,None]),axis=1)\n",
    "    # concatenating (X,y) of all training set and one test set\n",
    "    x_train_test_concat=np.concatenate((x_train_concat,x_test_add))\n",
    "    # concatenating y of training set and one test set\n",
    "    y_concat=np.concatenate((y_train,labels[j:j+1]))\n",
    "    # assign size of CF_score array\n",
    "    CF_score=np.zeros(x_train_test_concat.shape[0])\n",
    "    # iterate through each (x,y) of set and find distance\n",
    "    for k in range(x_train_test_concat.shape[0]):\n",
    "        arr_same=[]\n",
    "        arr_diff=[]\n",
    "        for l in range(x_train_test_concat.shape[0]):\n",
    "            if k!=l:\n",
    "                # find distance between sample of same class\n",
    "                if x_train_test_concat[k,-1]==y_concat[l]:\n",
    "                    arr_same.append(la.norm(x_train_test_concat[k,:-1]-x_train_test_concat[l,:-1]))\n",
    "                # find distance between sample of different class\n",
    "                else:\n",
    "                    arr_diff.append(la.norm(x_train_test_concat[k,:-1]-x_train_test_concat[l,:-1]))\n",
    "    # exception handling for ZeroDivisionError\n",
    "    # using formula -(distance between nearest sample of same class)/(distance between nearest sample of diff class)\n",
    "        try:\n",
    "            CF_score[k]=(min(arr_diff)/min(arr_same)) \n",
    "        except ZeroDivisionError:\n",
    "            CF_score[k]=np.inf\n",
    "    return CF_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definition - calculation of P value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating p value of each CF_score array\n",
    "def p_value(CF_score):\n",
    "    count=0\n",
    "    for m in range(CF_score.shape[0]):\n",
    "    \n",
    "        if CF_score[m]<=CF_score[-1]:\n",
    "            count+=1\n",
    "    p_value=(count/CF_score.shape[0])\n",
    "    return p_value\n",
    "import numpy as np\n",
    "p_value(np.array([1,2,3,6,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definition - calculation of P value for every label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.68141593,  0.00884956,  0.00884956],\n",
       "       [ 0.7079646 ,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.60176991,  0.00884956],\n",
       "       [ 0.00884956,  0.6460177 ,  0.00884956],\n",
       "       [ 0.00884956,  0.00884956,  0.33628319],\n",
       "       [ 0.59292035,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.00884956,  0.08849558],\n",
       "       [ 0.00884956,  0.00884956,  0.69911504],\n",
       "       [ 0.00884956,  0.00884956,  0.33628319],\n",
       "       [ 0.00884956,  0.44247788,  0.00884956],\n",
       "       [ 0.79646018,  0.00884956,  0.00884956],\n",
       "       [ 0.84955752,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.00884956,  0.17699115],\n",
       "       [ 0.00884956,  0.42477876,  0.00884956],\n",
       "       [ 0.75221239,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.00884956,  0.08849558],\n",
       "       [ 0.00884956,  0.00884956,  0.2920354 ],\n",
       "       [ 0.78761062,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.30088496,  0.00884956],\n",
       "       [ 0.00884956,  0.44247788,  0.00884956],\n",
       "       [ 0.00884956,  0.02654867,  0.07964602],\n",
       "       [ 0.00884956,  0.49557522,  0.00884956],\n",
       "       [ 0.85840708,  0.00884956,  0.00884956],\n",
       "       [ 0.69911504,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.01769912,  0.08849558],\n",
       "       [ 0.79646018,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.00884956,  0.46017699],\n",
       "       [ 0.00884956,  0.00884956,  0.45132743],\n",
       "       [ 0.00884956,  0.00884956,  0.47787611],\n",
       "       [ 0.00884956,  0.00884956,  0.4159292 ],\n",
       "       [ 0.00884956,  0.00884956,  0.43362832],\n",
       "       [ 1.        ,  0.00884956,  0.00884956],\n",
       "       [ 0.84070796,  0.00884956,  0.00884956],\n",
       "       [ 0.00884956,  0.19469027,  0.00884956],\n",
       "       [ 0.00884956,  0.6460177 ,  0.00884956],\n",
       "       [ 0.00884956,  0.00884956,  0.4159292 ],\n",
       "       [ 0.82300885,  0.00884956,  0.00884956],\n",
       "       [ 0.82300885,  0.00884956,  0.00884956]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculation of p_value of each test sample for every label\n",
    "def p_value_array(X_train,X_test,y_train,y_test,labels):\n",
    "    \n",
    "    labels_array=np.zeros((X_test.shape[0],labels.shape[0]))\n",
    "    for i in range(X_test.shape[0]):\n",
    "        for j in range(labels.shape[0]):\n",
    "            labels_array[i,j]=p_value(conformity_score(X_train,y_train,X_test,y_test,i,j,labels))\n",
    "    return labels_array \n",
    "\n",
    "labels=np.unique(y_train)\n",
    "p_value_array(X_train,X_test,y_train,y_test,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function definition - calculation of average false P value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation of average false p_value\n",
    "def average_false_pvalue(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    labels=np.unique(y_train)\n",
    "    p_value_array1=p_value_array(X_train,X_test,y_train,y_test,labels)\n",
    "    sum=0\n",
    "    for i in range(p_value_array1.shape[0]):\n",
    "        for j in range(labels.shape[0]):\n",
    "            # summation of false_pvalues \n",
    "            if labels[j]!=y_test[i]:\n",
    "                sum+=p_value_array1[i,j]\n",
    "    # average of false_p_value\n",
    "    return (sum/(X_test.shape[0]*(labels.shape[0]-1))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculation of average false P value of iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average false P_value of iris data set is  0.0109455053563\n",
      "\n",
      "calculated in:  8.28 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris['data'],iris['target'],random_state=503)\n",
    "print('Average false P_value of iris data set is ',average_false_pvalue(X_train,X_test,y_train,y_test))\n",
    "print('\\ncalculated in: ',\"%.2f\" %(time.time() - start),\"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculation of average false P value of ionosphere dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average false P_value of iris data set is  0.0636191460055\n",
      "\n",
      "predicted in:  72.15 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=503)\n",
    "print('Average false P_value of ionoshphere data set is ',average_false_pvalue(X_train,X_test,y_train,y_test))\n",
    "print('\\calculated in: ',\"%.2f\" %(time.time() - start),\"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
